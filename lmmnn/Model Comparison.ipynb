{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--xla_gpu_cuda_data_dir=C:/Users/AndrejTschalzev/anaconda3/Library/bin\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:/Users/AndrejTschalzev/Desktop/InES/Mixed_Effects/menn/model\")\n",
    "# sys.path.append(\"C:/Users/AndrejTschalzev/Desktop/InES/Mixed_Effects/lmmnn-main/lmmnn/\")\n",
    "sys.path.append(\"C:/Users/AndrejTschalzev/Desktop/InES/Mixed_Effects/Simchoni Repo/lmmnn/lmmnn\")\n",
    "import os\n",
    "aPath = '--xla_gpu_cuda_data_dir=C:/Users/AndrejTschalzev/anaconda3/Library/bin'\n",
    "print(aPath)\n",
    "os.environ['XLA_FLAGS'] = aPath\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from MENBernoulli import MEFFNN_Bernoulli\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense,LSTM,GRU,Dropout, Flatten, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# TODO: Change following import!!!\n",
    "#from utils import generate_data\n",
    "from utils import generate_data \n",
    "from layers import NLL\n",
    "from nn import reg_nn_lmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load/Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_fixed_effects\": 10,\n",
    "    \"fixed_intercept\": 1,\n",
    "    \"X_non_linear\": True,\n",
    "    \"Z_non_linear\": False,\n",
    "    \"Z_embed_dim_pct\": 10,\n",
    "    \"n_per_cat\": 3,\n",
    "    \"test_size\": 0.2,\n",
    "}\n",
    "\n",
    "\n",
    "N = 100000\n",
    "d = params[\"n_fixed_effects\"]\n",
    "q = 1000\n",
    "sig2b = 1.0\n",
    "mode = \"glmm\"\n",
    "\n",
    "X_train, X_test, y_train, y_test, x_cols, dist_matrix, time2measure_dict = generate_data(mode=mode, qs=[q], sig2e=1, sig2bs=[sig2b], sig2bs_spatial=[], q_spatial=[], N=N, rhos=None, p_censor=None, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dataframes for LMMNN of Simchoni\n",
    "X_train_lmmnn = X_train.copy()\n",
    "X_test_lmmnn = X_test.copy()\n",
    "y_train_lmmnn = y_train.copy()\n",
    "y_test_lmmnn = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataframes for other models\n",
    "Z_train = X_train[\"z0\"].values\n",
    "X_train = X_train[x_cols].astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "Z_test = X_test[\"z0\"].values\n",
    "X_test = X_test[x_cols].astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dataframes for MENN \n",
    "X_train_menn = X_train.copy()\n",
    "X_test_menn = X_test.copy()\n",
    "y_train_menn = y_train.copy()\n",
    "y_test_menn = y_test.copy()\n",
    "Z_train_menn = Z_train.copy()\n",
    "Z_test_menn = Z_test.copy()\n",
    "\n",
    "# set dataframes for Target Encoding Model\n",
    "X_train_te = X_train.copy()\n",
    "X_test_te = X_test.copy()\n",
    "y_train_te = y_train.copy()\n",
    "y_test_te = y_test.copy()\n",
    "Z_train_te = Z_train.copy()\n",
    "Z_test_te = Z_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Standard Neural Network without Random Effects Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "800/800 [==============================] - 3s 2ms/step - loss: 0.9229 - accuracy: 0.5972\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.6301 - accuracy: 0.6387\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.6237 - accuracy: 0.6443\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.6164 - accuracy: 0.6513\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.6093 - accuracy: 0.6575\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.6026 - accuracy: 0.6620\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.5971 - accuracy: 0.6672\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.5915 - accuracy: 0.6733\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.5873 - accuracy: 0.6779\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.5840 - accuracy: 0.6804\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.5812 - accuracy: 0.6831\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.5791 - accuracy: 0.6844\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.5772 - accuracy: 0.6869\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.5760 - accuracy: 0.6867\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.5748 - accuracy: 0.6885\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.5741 - accuracy: 0.6872\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.5730 - accuracy: 0.6889\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.5719 - accuracy: 0.6899\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.5712 - accuracy: 0.6900\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.5707 - accuracy: 0.6901\n",
      "Accuracy: 67.72%\n"
     ]
    }
   ],
   "source": [
    "# simple model with 1 hidden layer\n",
    "model_simple = Sequential()\n",
    "model_simple.add(Dense(100, activation='relu'))\n",
    "model_simple.add(Dense(50, activation='sigmoid'))\n",
    "model_simple.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "model_simple.fit(X_train, y_train, epochs=20, batch_size=100)\n",
    "# Final evaluation of the model\n",
    "scores = model_simple.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) LMMNN of Simchoni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = [col for col in X_train.columns if col not in ['z0','z1','z2']]\n",
    "batch = 100\n",
    "epochs = 20\n",
    "patience = 10\n",
    "qs=[q]\n",
    "q_spatial=[]\n",
    "n_neurons = [100,50]\n",
    "dropout = None\n",
    "activation = 'relu'\n",
    "mode = 'glmm'\n",
    "n_sig2bs = 1\n",
    "n_sig2bs_spatial = 0\n",
    "est_cors = []\n",
    "dist_matrix = None\n",
    "time2measure_dict = None\n",
    "spatial_embed_neurons = None\n",
    "verbose = True\n",
    "Z_non_linear = False\n",
    "log_params = False\n",
    "idx = None\n",
    "Z_embed_dim_pct = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "720/720 [==============================] - 11s 12ms/step - loss: 58.5966 - val_loss: 55.3959\n",
      "Epoch 2/20\n",
      "720/720 [==============================] - 8s 12ms/step - loss: 53.6160 - val_loss: 52.1782\n",
      "Epoch 3/20\n",
      "720/720 [==============================] - 9s 12ms/step - loss: 51.8880 - val_loss: 51.4472\n",
      "Epoch 4/20\n",
      "720/720 [==============================] - 8s 12ms/step - loss: 51.4443 - val_loss: 51.2510\n",
      "Epoch 5/20\n",
      "720/720 [==============================] - 8s 11ms/step - loss: 51.2681 - val_loss: 51.1577\n",
      "Epoch 6/20\n",
      "720/720 [==============================] - 9s 12ms/step - loss: 51.1657 - val_loss: 51.1195\n",
      "Epoch 7/20\n",
      "720/720 [==============================] - 9s 12ms/step - loss: 51.1007 - val_loss: 51.0864\n",
      "Epoch 8/20\n",
      "720/720 [==============================] - 8s 11ms/step - loss: 51.0516 - val_loss: 51.0792\n",
      "Epoch 9/20\n",
      "720/720 [==============================] - 8s 11ms/step - loss: 51.0121 - val_loss: 51.0721\n",
      "Epoch 10/20\n",
      "720/720 [==============================] - 9s 12ms/step - loss: 50.9782 - val_loss: 51.0711\n",
      "Epoch 11/20\n",
      "720/720 [==============================] - 9s 12ms/step - loss: 50.9437 - val_loss: 51.0661\n",
      "Epoch 12/20\n",
      "720/720 [==============================] - 9s 12ms/step - loss: 50.9131 - val_loss: 51.0594\n",
      "Epoch 13/20\n",
      "720/720 [==============================] - 8s 11ms/step - loss: 50.8815 - val_loss: 51.0503\n",
      "Epoch 14/20\n",
      "720/720 [==============================] - 8s 11ms/step - loss: 50.8532 - val_loss: 51.0422\n",
      "Epoch 15/20\n",
      "720/720 [==============================] - 8s 12ms/step - loss: 50.8268 - val_loss: 51.0371\n",
      "Epoch 16/20\n",
      "720/720 [==============================] - 9s 12ms/step - loss: 50.7990 - val_loss: 51.0331\n",
      "Epoch 17/20\n",
      "720/720 [==============================] - 8s 11ms/step - loss: 50.7754 - val_loss: 51.0246\n",
      "Epoch 18/20\n",
      "720/720 [==============================] - 8s 11ms/step - loss: 50.7509 - val_loss: 51.0225\n",
      "Epoch 19/20\n",
      "720/720 [==============================] - 8s 11ms/step - loss: 50.7233 - val_loss: 51.0189\n",
      "Epoch 20/20\n",
      "720/720 [==============================] - 8s 11ms/step - loss: 50.6976 - val_loss: 51.0286\n"
     ]
    }
   ],
   "source": [
    "y_pred, sigmas, rhos, weibull, n_epochs = reg_nn_lmm(\n",
    "            X_train_lmmnn, X_test_lmmnn, y_train_lmmnn, y_test_lmmnn, qs, q_spatial, x_cols, batch, epochs, patience,\n",
    "            n_neurons, dropout, activation, mode,\n",
    "            n_sig2bs, n_sig2bs_spatial, est_cors, dist_matrix, spatial_embed_neurons, verbose, Z_non_linear, Z_embed_dim_pct, log_params, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74845"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# round predictions to closest integer and compute accuracy\n",
    "y_pred_class = []\n",
    "for n in y_pred:\n",
    "    y_pred_class.append(round(n))\n",
    "\n",
    "acc(y_test_lmmnn, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) MENN of Andrej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-Up Iteration:   0 Acceptance Rate: 1.000\n",
      "Warm-Up Iteration: 999 Acceptance Rate: 1.000\n",
      "Iteration:    0 Acceptance Rate: 1.000 Loss: 53246.059\n",
      "Iteration:  500 Acceptance Rate: 0.994 Loss: 46992.707\n",
      "Iteration: 1000 Acceptance Rate: 0.995 Loss: 44494.578\n",
      "Iteration: 1500 Acceptance Rate: 0.996 Loss: 42192.867\n",
      "Iteration: 2000 Acceptance Rate: 0.997 Loss: 40920.500\n",
      "Iteration: 2500 Acceptance Rate: 0.997 Loss: 40323.957\n",
      "Iteration: 3000 Acceptance Rate: 0.997 Loss: 39978.156\n",
      "Iteration: 3500 Acceptance Rate: 0.997 Loss: 39875.992\n",
      "Iteration: 4000 Acceptance Rate: 0.997 Loss: 39750.750\n",
      "Iteration: 4500 Acceptance Rate: 0.996 Loss: 39747.520\n",
      "Iteration: 4999 Acceptance Rate: 0.996 Loss: 39581.137\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(learning_rate=.0001)#, decay=0.0001)\n",
    "\n",
    "model_jointdist = MEFFNN_Bernoulli(d,q, layers=[100,50])\n",
    "model_jointdist.fit(X_train_menn, y_train_menn, Z_train_menn, optimizer=optimizer, num_warmup_iters=1000, num_iters=5000, print_warmup=1500, print_training=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model_jointdist.predict(X_train_menn,Z_train_menn)\n",
    "y_train_pred_fe = model_jointdist.predict(X_train_menn)\n",
    "y_test_pred = model_jointdist.predict(X_test_menn,Z_test_menn)\n",
    "y_test_pred_fe = model_jointdist.predict(X_test_menn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.769125\n",
      "Accuracy (only FE):  0.7036125\n",
      "Correlation mean occupation/raneffs:  0.9843849924029732\n",
      "Meaningful RE indicator value:  0.95\n",
      "STd of RE's:  1.0236143\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on Train\n",
    "print(\"Accuracy: \", acc(y_train_menn, np.round(y_train_pred)))\n",
    "print(\"Accuracy (only FE): \", acc(y_train_menn, np.round(y_train_pred_fe)))\n",
    "\n",
    "mean_y_group = pd.DataFrame([Z_train_menn,y_train_menn]).transpose().groupby(0).mean().values.ravel()\n",
    "print(\"Correlation mean occupation/raneffs: \", np.corrcoef([model_jointdist.random_effects, mean_y_group])[0,1])\n",
    "\n",
    "print(\"Meaningful RE indicator value: \", (np.corrcoef([model_jointdist.random_effects, mean_y_group])[0,1]-np.corrcoef([np.random.randn(model_jointdist.random_effects.shape[0]), model_jointdist.random_effects])[0,1]).round(3))\n",
    "\n",
    "print(\"STd of RE's: \", model_jointdist._stddev_z0.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.74735\n",
      "Accuracy (only FE):  0.68905\n",
      "Correlation mean occupation/raneffs:  0.7704344211182708\n",
      "Meaningful RE indicator value:  0.736\n",
      "STd of RE's:  1.0236143\n"
     ]
    }
   ],
   "source": [
    "## Evaluation on Test\n",
    "print(\"Accuracy: \", acc(y_test_menn, np.round(y_test_pred)))\n",
    "print(\"Accuracy (only FE): \", acc(y_test_menn, np.round(y_test_pred_fe)))\n",
    "\n",
    "mean_y_group = pd.DataFrame([Z_test_menn,y_test_menn]).transpose().groupby(0).mean().values.ravel()\n",
    "print(\"Correlation mean occupation/raneffs: \", np.corrcoef([model_jointdist.random_effects, mean_y_group])[0,1])\n",
    "\n",
    "### Simple check if RE's correlation to group means is not random - values close to 1 indicate high meaningfulness, while close to zero indicates randomness\n",
    "print(\"Meaningful RE indicator value: \", (np.corrcoef([model_jointdist.random_effects, mean_y_group])[0,1]-np.corrcoef([np.random.randn(model_jointdist.random_effects.shape[0]), model_jointdist.random_effects])[0,1]).round(3))\n",
    "\n",
    "print(\"STd of RE's: \", model_jointdist._stddev_z0.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_te['z0'] = Z_train_te\n",
    "X_test_te['z0'] = Z_test_te\n",
    "X_train_te['target'] = y_train_te\n",
    "X_test_te['target'] = y_test_te\n",
    "\n",
    "df_train = X_train_te\n",
    "df_test = X_test_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform random effect variable to string\n",
    "df_train.z0 = df_train.z0.astype(str)\n",
    "df_test.z0 = df_test.z0.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AndrejTschalzev\\anaconda3\\lib\\site-packages\\category_encoders\\target_encoder.py:92: FutureWarning: Default parameter min_samples_leaf will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter min_samples_leaf will change in version 2.6.\"\n",
      "C:\\Users\\AndrejTschalzev\\anaconda3\\lib\\site-packages\\category_encoders\\target_encoder.py:97: FutureWarning: Default parameter smoothing will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter smoothing will change in version 2.6.\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>z0</th>\n",
       "      <th>target</th>\n",
       "      <th>RE Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67289</th>\n",
       "      <td>-0.988776</td>\n",
       "      <td>0.892862</td>\n",
       "      <td>0.069132</td>\n",
       "      <td>-0.872051</td>\n",
       "      <td>-0.410435</td>\n",
       "      <td>-0.492521</td>\n",
       "      <td>-0.602586</td>\n",
       "      <td>0.549388</td>\n",
       "      <td>-0.492385</td>\n",
       "      <td>-0.583401</td>\n",
       "      <td>674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.278049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61772</th>\n",
       "      <td>-0.527640</td>\n",
       "      <td>-0.966804</td>\n",
       "      <td>-0.178469</td>\n",
       "      <td>0.814343</td>\n",
       "      <td>0.857220</td>\n",
       "      <td>0.208040</td>\n",
       "      <td>-0.114703</td>\n",
       "      <td>0.417908</td>\n",
       "      <td>-0.955980</td>\n",
       "      <td>0.770787</td>\n",
       "      <td>619</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.481481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58427</th>\n",
       "      <td>-0.798362</td>\n",
       "      <td>-0.215860</td>\n",
       "      <td>0.610483</td>\n",
       "      <td>-0.600022</td>\n",
       "      <td>0.181420</td>\n",
       "      <td>-0.009999</td>\n",
       "      <td>0.352461</td>\n",
       "      <td>0.090399</td>\n",
       "      <td>0.702602</td>\n",
       "      <td>0.983926</td>\n",
       "      <td>586</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.670886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75760</th>\n",
       "      <td>0.057209</td>\n",
       "      <td>0.740510</td>\n",
       "      <td>-0.216223</td>\n",
       "      <td>0.800969</td>\n",
       "      <td>0.242166</td>\n",
       "      <td>0.734752</td>\n",
       "      <td>0.370333</td>\n",
       "      <td>-0.963477</td>\n",
       "      <td>-0.010866</td>\n",
       "      <td>0.126177</td>\n",
       "      <td>750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.278481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52771</th>\n",
       "      <td>0.385098</td>\n",
       "      <td>0.456060</td>\n",
       "      <td>-0.201385</td>\n",
       "      <td>-0.345627</td>\n",
       "      <td>0.250710</td>\n",
       "      <td>0.362323</td>\n",
       "      <td>-0.272217</td>\n",
       "      <td>-0.588831</td>\n",
       "      <td>-0.653261</td>\n",
       "      <td>-0.972687</td>\n",
       "      <td>531</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.670455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34953</th>\n",
       "      <td>-0.787268</td>\n",
       "      <td>-0.243127</td>\n",
       "      <td>0.792764</td>\n",
       "      <td>0.208276</td>\n",
       "      <td>-0.506343</td>\n",
       "      <td>0.207648</td>\n",
       "      <td>0.236252</td>\n",
       "      <td>0.470231</td>\n",
       "      <td>0.817081</td>\n",
       "      <td>-0.762650</td>\n",
       "      <td>358</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.317829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51333</th>\n",
       "      <td>0.031326</td>\n",
       "      <td>0.037340</td>\n",
       "      <td>-0.229243</td>\n",
       "      <td>0.498082</td>\n",
       "      <td>0.336013</td>\n",
       "      <td>0.225062</td>\n",
       "      <td>0.325180</td>\n",
       "      <td>-0.405215</td>\n",
       "      <td>0.890586</td>\n",
       "      <td>-0.328829</td>\n",
       "      <td>520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.654321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46890</th>\n",
       "      <td>0.816116</td>\n",
       "      <td>0.270360</td>\n",
       "      <td>0.554139</td>\n",
       "      <td>0.784908</td>\n",
       "      <td>-0.004384</td>\n",
       "      <td>-0.219889</td>\n",
       "      <td>-0.272515</td>\n",
       "      <td>0.600443</td>\n",
       "      <td>0.201243</td>\n",
       "      <td>-0.737825</td>\n",
       "      <td>474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.243386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37331</th>\n",
       "      <td>0.164079</td>\n",
       "      <td>0.286051</td>\n",
       "      <td>-0.201195</td>\n",
       "      <td>-0.413490</td>\n",
       "      <td>-0.428126</td>\n",
       "      <td>-0.380729</td>\n",
       "      <td>0.098788</td>\n",
       "      <td>0.037482</td>\n",
       "      <td>0.161009</td>\n",
       "      <td>0.761972</td>\n",
       "      <td>379</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.404255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42789</th>\n",
       "      <td>-0.952456</td>\n",
       "      <td>-0.168451</td>\n",
       "      <td>0.458185</td>\n",
       "      <td>-0.530791</td>\n",
       "      <td>0.274474</td>\n",
       "      <td>0.636711</td>\n",
       "      <td>0.866294</td>\n",
       "      <td>0.491452</td>\n",
       "      <td>0.926187</td>\n",
       "      <td>0.931323</td>\n",
       "      <td>436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             X0        X1        X2        X3        X4        X5        X6  \\\n",
       "67289 -0.988776  0.892862  0.069132 -0.872051 -0.410435 -0.492521 -0.602586   \n",
       "61772 -0.527640 -0.966804 -0.178469  0.814343  0.857220  0.208040 -0.114703   \n",
       "58427 -0.798362 -0.215860  0.610483 -0.600022  0.181420 -0.009999  0.352461   \n",
       "75760  0.057209  0.740510 -0.216223  0.800969  0.242166  0.734752  0.370333   \n",
       "52771  0.385098  0.456060 -0.201385 -0.345627  0.250710  0.362323 -0.272217   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "34953 -0.787268 -0.243127  0.792764  0.208276 -0.506343  0.207648  0.236252   \n",
       "51333  0.031326  0.037340 -0.229243  0.498082  0.336013  0.225062  0.325180   \n",
       "46890  0.816116  0.270360  0.554139  0.784908 -0.004384 -0.219889 -0.272515   \n",
       "37331  0.164079  0.286051 -0.201195 -0.413490 -0.428126 -0.380729  0.098788   \n",
       "42789 -0.952456 -0.168451  0.458185 -0.530791  0.274474  0.636711  0.866294   \n",
       "\n",
       "             X7        X8        X9   z0  target  RE Encoded  \n",
       "67289  0.549388 -0.492385 -0.583401  674     0.0    0.278049  \n",
       "61772  0.417908 -0.955980  0.770787  619     1.0    0.481481  \n",
       "58427  0.090399  0.702602  0.983926  586     1.0    0.670886  \n",
       "75760 -0.963477 -0.010866  0.126177  750     0.0    0.278481  \n",
       "52771 -0.588831 -0.653261 -0.972687  531     1.0    0.670455  \n",
       "...         ...       ...       ...  ...     ...         ...  \n",
       "34953  0.470231  0.817081 -0.762650  358     1.0    0.317829  \n",
       "51333 -0.405215  0.890586 -0.328829  520     0.0    0.654321  \n",
       "46890  0.600443  0.201243 -0.737825  474     0.0    0.243386  \n",
       "37331  0.037482  0.161009  0.761972  379     1.0    0.404255  \n",
       "42789  0.491452  0.926187  0.931323  436     0.0    0.317757  \n",
       "\n",
       "[80000 rows x 13 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = TargetEncoder()\n",
    "df_train['RE Encoded'] = encoder.fit_transform(df_train['z0'], df_train['target']) # fit_transform on train data\n",
    "df_test['RE Encoded'] = encoder.transform(df_test['z0'], df_test['target']) # transform on test data\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop z0\n",
    "df_train = df_train.drop(['z0'], axis=1)\n",
    "df_test = df_test.drop(['z0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define y and X variables\n",
    "y_train_te = df_train['target']\n",
    "X_train_te = df_train.drop(['target'], axis=1)\n",
    "y_test_te = df_test['target']\n",
    "X_test_te = df_test.drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.8353 - accuracy: 0.6427\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.5606 - accuracy: 0.7131\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.5504 - accuracy: 0.7190\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.5427 - accuracy: 0.7244\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.5344 - accuracy: 0.7306\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.5276 - accuracy: 0.7355\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.5209 - accuracy: 0.7402\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.5153 - accuracy: 0.7454\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.5109 - accuracy: 0.7480\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.5072 - accuracy: 0.7518\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.5028 - accuracy: 0.7529\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.4978 - accuracy: 0.7564\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.4947 - accuracy: 0.7581\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.4927 - accuracy: 0.7592\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.4905 - accuracy: 0.7613\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.4892 - accuracy: 0.7614\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.4884 - accuracy: 0.7617\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.4875 - accuracy: 0.7617\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.4870 - accuracy: 0.7619\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.4865 - accuracy: 0.7619\n",
      "Accuracy: 74.77%\n"
     ]
    }
   ],
   "source": [
    "# simple model with 1 hidden layer\n",
    "model_simple = Sequential()\n",
    "model_simple.add(Dense(100, activation='relu'))\n",
    "model_simple.add(Dense(50, activation='sigmoid'))\n",
    "model_simple.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "model_simple.fit(X_train_te, y_train_te, epochs=20, batch_size=100)\n",
    "# Final evaluation of the model\n",
    "scores = model_simple.evaluate(X_test_te, y_test_te, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
